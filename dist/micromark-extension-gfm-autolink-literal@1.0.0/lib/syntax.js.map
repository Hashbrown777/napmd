{"version":3,"file":"syntax.js","sources":["../../../node_modules/micromark-extension-gfm-autolink-literal/lib/syntax.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Extension} Extension\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Previous} Previous\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Event} Event\n * @typedef {import('micromark-util-types').Code} Code\n */\nimport {\n  asciiAlpha,\n  asciiAlphanumeric,\n  asciiControl,\n  asciiDigit,\n  markdownLineEndingOrSpace,\n  markdownLineEnding,\n  unicodePunctuation,\n  unicodeWhitespace\n} from 'micromark-util-character'\nconst www = {\n  tokenize: tokenizeWww,\n  partial: true\n}\nconst domain = {\n  tokenize: tokenizeDomain,\n  partial: true\n}\nconst path = {\n  tokenize: tokenizePath,\n  partial: true\n}\nconst punctuation = {\n  tokenize: tokenizePunctuation,\n  partial: true\n}\nconst namedCharacterReference = {\n  tokenize: tokenizeNamedCharacterReference,\n  partial: true\n}\nconst wwwAutolink = {\n  tokenize: tokenizeWwwAutolink,\n  previous: previousWww\n}\nconst httpAutolink = {\n  tokenize: tokenizeHttpAutolink,\n  previous: previousHttp\n}\nconst emailAutolink = {\n  tokenize: tokenizeEmailAutolink,\n  previous: previousEmail\n}\n/** @type {ConstructRecord} */\n\nconst text = {}\n/** @type {Extension} */\n\nexport const gfmAutolinkLiteral = {\n  text\n}\nlet code = 48 // Add alphanumerics.\n\nwhile (code < 123) {\n  text[code] = emailAutolink\n  code++\n  if (code === 58) code = 65\n  else if (code === 91) code = 97\n}\n\ntext[43] = emailAutolink\ntext[45] = emailAutolink\ntext[46] = emailAutolink\ntext[95] = emailAutolink\ntext[72] = [emailAutolink, httpAutolink]\ntext[104] = [emailAutolink, httpAutolink]\ntext[87] = [emailAutolink, wwwAutolink]\ntext[119] = [emailAutolink, wwwAutolink]\n/** @type {Tokenizer} */\n\nfunction tokenizeEmailAutolink(effects, ok, nok) {\n  const self = this\n  /** @type {boolean} */\n\n  let hasDot\n  /** @type {boolean|undefined} */\n\n  let hasDigitInLastSegment\n  return start\n  /** @type {State} */\n\n  function start(code) {\n    if (\n      !gfmAtext(code) ||\n      !previousEmail(self.previous) ||\n      previousUnbalanced(self.events)\n    ) {\n      return nok(code)\n    }\n\n    effects.enter('literalAutolink')\n    effects.enter('literalAutolinkEmail')\n    return atext(code)\n  }\n  /** @type {State} */\n\n  function atext(code) {\n    if (gfmAtext(code)) {\n      effects.consume(code)\n      return atext\n    }\n\n    if (code === 64) {\n      effects.consume(code)\n      return label\n    }\n\n    return nok(code)\n  }\n  /** @type {State} */\n\n  function label(code) {\n    if (code === 46) {\n      return effects.check(punctuation, done, dotContinuation)(code)\n    }\n\n    if (code === 45 || code === 95) {\n      return effects.check(punctuation, nok, dashOrUnderscoreContinuation)(code)\n    }\n\n    if (asciiAlphanumeric(code)) {\n      if (!hasDigitInLastSegment && asciiDigit(code)) {\n        hasDigitInLastSegment = true\n      }\n\n      effects.consume(code)\n      return label\n    }\n\n    return done(code)\n  }\n  /** @type {State} */\n\n  function dotContinuation(code) {\n    effects.consume(code)\n    hasDot = true\n    hasDigitInLastSegment = undefined\n    return label\n  }\n  /** @type {State} */\n\n  function dashOrUnderscoreContinuation(code) {\n    effects.consume(code)\n    return afterDashOrUnderscore\n  }\n  /** @type {State} */\n\n  function afterDashOrUnderscore(code) {\n    if (code === 46) {\n      return effects.check(punctuation, nok, dotContinuation)(code)\n    }\n\n    return label(code)\n  }\n  /** @type {State} */\n\n  function done(code) {\n    if (hasDot && !hasDigitInLastSegment) {\n      effects.exit('literalAutolinkEmail')\n      effects.exit('literalAutolink')\n      return ok(code)\n    }\n\n    return nok(code)\n  }\n}\n/** @type {Tokenizer} */\n\nfunction tokenizeWwwAutolink(effects, ok, nok) {\n  const self = this\n  return start\n  /** @type {State} */\n\n  function start(code) {\n    if (\n      (code !== 87 && code !== 119) ||\n      !previousWww(self.previous) ||\n      previousUnbalanced(self.events)\n    ) {\n      return nok(code)\n    }\n\n    effects.enter('literalAutolink')\n    effects.enter('literalAutolinkWww') // For `www.` we check instead of attempt, because when it matches, GH\n    // treats it as part of a domain (yes, it says a valid domain must come\n    // after `www.`, but that’s not how it’s implemented by them).\n\n    return effects.check(\n      www,\n      effects.attempt(domain, effects.attempt(path, done), nok),\n      nok\n    )(code)\n  }\n  /** @type {State} */\n\n  function done(code) {\n    effects.exit('literalAutolinkWww')\n    effects.exit('literalAutolink')\n    return ok(code)\n  }\n}\n/** @type {Tokenizer} */\n\nfunction tokenizeHttpAutolink(effects, ok, nok) {\n  const self = this\n  return start\n  /** @type {State} */\n\n  function start(code) {\n    if (\n      (code !== 72 && code !== 104) ||\n      !previousHttp(self.previous) ||\n      previousUnbalanced(self.events)\n    ) {\n      return nok(code)\n    }\n\n    effects.enter('literalAutolink')\n    effects.enter('literalAutolinkHttp')\n    effects.consume(code)\n    return t1\n  }\n  /** @type {State} */\n\n  function t1(code) {\n    if (code === 84 || code === 116) {\n      effects.consume(code)\n      return t2\n    }\n\n    return nok(code)\n  }\n  /** @type {State} */\n\n  function t2(code) {\n    if (code === 84 || code === 116) {\n      effects.consume(code)\n      return p\n    }\n\n    return nok(code)\n  }\n  /** @type {State} */\n\n  function p(code) {\n    if (code === 80 || code === 112) {\n      effects.consume(code)\n      return s\n    }\n\n    return nok(code)\n  }\n  /** @type {State} */\n\n  function s(code) {\n    if (code === 83 || code === 115) {\n      effects.consume(code)\n      return colon\n    }\n\n    return colon(code)\n  }\n  /** @type {State} */\n\n  function colon(code) {\n    if (code === 58) {\n      effects.consume(code)\n      return slash1\n    }\n\n    return nok(code)\n  }\n  /** @type {State} */\n\n  function slash1(code) {\n    if (code === 47) {\n      effects.consume(code)\n      return slash2\n    }\n\n    return nok(code)\n  }\n  /** @type {State} */\n\n  function slash2(code) {\n    if (code === 47) {\n      effects.consume(code)\n      return after\n    }\n\n    return nok(code)\n  }\n  /** @type {State} */\n\n  function after(code) {\n    return code === null ||\n      asciiControl(code) ||\n      unicodeWhitespace(code) ||\n      unicodePunctuation(code)\n      ? nok(code)\n      : effects.attempt(domain, effects.attempt(path, done), nok)(code)\n  }\n  /** @type {State} */\n\n  function done(code) {\n    effects.exit('literalAutolinkHttp')\n    effects.exit('literalAutolink')\n    return ok(code)\n  }\n}\n/** @type {Tokenizer} */\n\nfunction tokenizeWww(effects, ok, nok) {\n  return start\n  /** @type {State} */\n\n  function start(code) {\n    effects.consume(code)\n    return w2\n  }\n  /** @type {State} */\n\n  function w2(code) {\n    if (code === 87 || code === 119) {\n      effects.consume(code)\n      return w3\n    }\n\n    return nok(code)\n  }\n  /** @type {State} */\n\n  function w3(code) {\n    if (code === 87 || code === 119) {\n      effects.consume(code)\n      return dot\n    }\n\n    return nok(code)\n  }\n  /** @type {State} */\n\n  function dot(code) {\n    if (code === 46) {\n      effects.consume(code)\n      return after\n    }\n\n    return nok(code)\n  }\n  /** @type {State} */\n\n  function after(code) {\n    return code === null || markdownLineEnding(code) ? nok(code) : ok(code)\n  }\n}\n/** @type {Tokenizer} */\n\nfunction tokenizeDomain(effects, ok, nok) {\n  /** @type {boolean|undefined} */\n  let hasUnderscoreInLastSegment\n  /** @type {boolean|undefined} */\n\n  let hasUnderscoreInLastLastSegment\n  return domain\n  /** @type {State} */\n\n  function domain(code) {\n    if (code === 38) {\n      return effects.check(\n        namedCharacterReference,\n        done,\n        punctuationContinuation\n      )(code)\n    }\n\n    if (code === 46 || code === 95) {\n      return effects.check(punctuation, done, punctuationContinuation)(code)\n    } // GH documents that only alphanumerics (other than `-`, `.`, and `_`) can\n    // occur, which sounds like ASCII only, but they also support `www.點看.com`,\n    // so that’s Unicode.\n    // Instead of some new production for Unicode alphanumerics, markdown\n    // already has that for Unicode punctuation and whitespace, so use those.\n\n    if (\n      code === null ||\n      asciiControl(code) ||\n      unicodeWhitespace(code) ||\n      (code !== 45 && unicodePunctuation(code))\n    ) {\n      return done(code)\n    }\n\n    effects.consume(code)\n    return domain\n  }\n  /** @type {State} */\n\n  function punctuationContinuation(code) {\n    if (code === 46) {\n      hasUnderscoreInLastLastSegment = hasUnderscoreInLastSegment\n      hasUnderscoreInLastSegment = undefined\n      effects.consume(code)\n      return domain\n    }\n\n    if (code === 95) hasUnderscoreInLastSegment = true\n    effects.consume(code)\n    return domain\n  }\n  /** @type {State} */\n\n  function done(code) {\n    if (!hasUnderscoreInLastLastSegment && !hasUnderscoreInLastSegment) {\n      return ok(code)\n    }\n\n    return nok(code)\n  }\n}\n/** @type {Tokenizer} */\n\nfunction tokenizePath(effects, ok) {\n  let balance = 0\n  return inPath\n  /** @type {State} */\n\n  function inPath(code) {\n    if (code === 38) {\n      return effects.check(\n        namedCharacterReference,\n        ok,\n        continuedPunctuation\n      )(code)\n    }\n\n    if (code === 40) {\n      balance++\n    }\n\n    if (code === 41) {\n      return effects.check(\n        punctuation,\n        parenAtPathEnd,\n        continuedPunctuation\n      )(code)\n    }\n\n    if (pathEnd(code)) {\n      return ok(code)\n    }\n\n    if (trailingPunctuation(code)) {\n      return effects.check(punctuation, ok, continuedPunctuation)(code)\n    }\n\n    effects.consume(code)\n    return inPath\n  }\n  /** @type {State} */\n\n  function continuedPunctuation(code) {\n    effects.consume(code)\n    return inPath\n  }\n  /** @type {State} */\n\n  function parenAtPathEnd(code) {\n    balance--\n    return balance < 0 ? ok(code) : continuedPunctuation(code)\n  }\n}\n/** @type {Tokenizer} */\n\nfunction tokenizeNamedCharacterReference(effects, ok, nok) {\n  return start\n  /** @type {State} */\n\n  function start(code) {\n    effects.consume(code)\n    return inside\n  }\n  /** @type {State} */\n\n  function inside(code) {\n    if (asciiAlpha(code)) {\n      effects.consume(code)\n      return inside\n    }\n\n    if (code === 59) {\n      effects.consume(code)\n      return after\n    }\n\n    return nok(code)\n  }\n  /** @type {State} */\n\n  function after(code) {\n    // If the named character reference is followed by the end of the path, it’s\n    // not continued punctuation.\n    return pathEnd(code) ? ok(code) : nok(code)\n  }\n}\n/** @type {Tokenizer} */\n\nfunction tokenizePunctuation(effects, ok, nok) {\n  return start\n  /** @type {State} */\n\n  function start(code) {\n    effects.consume(code)\n    return after\n  }\n  /** @type {State} */\n\n  function after(code) {\n    // Check the next.\n    if (trailingPunctuation(code)) {\n      effects.consume(code)\n      return after\n    } // If the punctuation marker is followed by the end of the path, it’s not\n    // continued punctuation.\n\n    return pathEnd(code) ? ok(code) : nok(code)\n  }\n}\n/**\n * @param {Code} code\n * @returns {boolean}\n */\n\nfunction trailingPunctuation(code) {\n  return (\n    code === 33 ||\n    code === 34 ||\n    code === 39 ||\n    code === 41 ||\n    code === 42 ||\n    code === 44 ||\n    code === 46 ||\n    code === 58 ||\n    code === 59 ||\n    code === 60 ||\n    code === 63 ||\n    code === 95 ||\n    code === 126\n  )\n}\n/**\n * @param {Code} code\n * @returns {boolean}\n */\n\nfunction pathEnd(code) {\n  return code === null || code === 60 || markdownLineEndingOrSpace(code)\n}\n/**\n * @param {Code} code\n * @returns {boolean}\n */\n\nfunction gfmAtext(code) {\n  return (\n    code === 43 ||\n    code === 45 ||\n    code === 46 ||\n    code === 95 ||\n    asciiAlphanumeric(code)\n  )\n}\n/** @type {Previous} */\n\nfunction previousWww(code) {\n  return (\n    code === null ||\n    code === 40 ||\n    code === 42 ||\n    code === 95 ||\n    code === 126 ||\n    markdownLineEndingOrSpace(code)\n  )\n}\n/** @type {Previous} */\n\nfunction previousHttp(code) {\n  return code === null || !asciiAlpha(code)\n}\n/** @type {Previous} */\n\nfunction previousEmail(code) {\n  return code !== 47 && previousHttp(code)\n}\n/**\n * @param {Event[]} events\n * @returns {boolean}\n */\n\nfunction previousUnbalanced(events) {\n  let index = events.length\n  let result = false\n\n  while (index--) {\n    const token = events[index][1]\n\n    if (\n      (token.type === 'labelLink' || token.type === 'labelImage') &&\n      !token._balanced\n    ) {\n      result = true\n      break\n    } // @ts-expect-error If we’ve seen this token, and it was marked as not\n    // having any unbalanced bracket before it, we can exit.\n\n    if (token._gfmAutolinkLiteralWalkedInto) {\n      result = false\n      break\n    }\n  }\n\n  if (events.length > 0 && !result) {\n    // @ts-expect-error Mark the last token as “walked into” w/o finding\n    // anything.\n    events[events.length - 1][1]._gfmAutolinkLiteralWalkedInto = true\n  }\n\n  return result\n}\n"],"names":["www","tokenize","effects","ok","nok","code","consume","w2","w3","dot","after","markdownLineEnding","partial","domain","hasUnderscoreInLastSegment","hasUnderscoreInLastLastSegment","check","namedCharacterReference","done","punctuationContinuation","punctuation","asciiControl","unicodeWhitespace","unicodePunctuation","undefined","path","balance","inPath","continuedPunctuation","parenAtPathEnd","pathEnd","trailingPunctuation","inside","asciiAlpha","wwwAutolink","self","this","previousWww","previous","previousUnbalanced","events","enter","attempt","exit","httpAutolink","previousHttp","t1","t2","p","s","colon","slash1","slash2","emailAutolink","hasDot","hasDigitInLastSegment","gfmAtext","previousEmail","atext","label","dotContinuation","dashOrUnderscoreContinuation","asciiAlphanumeric","asciiDigit","afterDashOrUnderscore","text","gfmAutolinkLiteral","markdownLineEndingOrSpace","index","length","result","token","type","_balanced","_gfmAutolinkLiteralWalkedInto"],"mappings":"6DAmBA,MAAMA,EAAM,CACVC,SA4SF,SAAqBC,EAASC,EAAIC,GAChC,OAGA,SAAeC,GAEb,OADAH,EAAQI,QAAQD,GACTE,GAIT,SAASA,EAAGF,GACV,OAAa,KAATA,GAAwB,MAATA,GACjBH,EAAQI,QAAQD,GACTG,GAGFJ,EAAIC,GAIb,SAASG,EAAGH,GACV,OAAa,KAATA,GAAwB,MAATA,GACjBH,EAAQI,QAAQD,GACTI,GAGFL,EAAIC,GAIb,SAASI,EAAIJ,GACX,OAAa,KAATA,GACFH,EAAQI,QAAQD,GACTK,GAGFN,EAAIC,GAIb,SAASK,EAAML,GACb,OAAgB,OAATA,GAAiBM,qBAAmBN,GAAQD,EAAIC,GAAQF,EAAGE,KApVpEO,SAAS,GAELC,EAAS,CACbZ,SAsVF,SAAwBC,EAASC,EAAIC,GAEnC,IAAIU,EAGAC,EACJ,OAAOF,EAGP,SAASA,EAAOR,GACd,OAAa,KAATA,EACKH,EAAQc,MACbC,EACAC,EACAC,EAHKjB,CAILG,GAGS,KAATA,GAAwB,KAATA,EACVH,EAAQc,MAAMI,EAAaF,EAAMC,EAAjCjB,CAA0DG,GAQxD,OAATA,GACAgB,eAAahB,IACbiB,oBAAkBjB,IACR,KAATA,GAAekB,qBAAmBlB,GAE5Ba,EAAKb,IAGdH,EAAQI,QAAQD,GACTQ,GAIT,SAASM,EAAwBd,GAC/B,OAAa,KAATA,GACFU,EAAiCD,EACjCA,OAA6BU,EAC7BtB,EAAQI,QAAQD,GACTQ,IAGI,KAATR,IAAaS,GAA6B,GAC9CZ,EAAQI,QAAQD,GACTQ,GAIT,SAASK,EAAKb,GACZ,OAAKU,GAAmCD,EAIjCV,EAAIC,GAHFF,EAAGE,KA7YdO,SAAS,GAELa,EAAO,CACXxB,SAkZF,SAAsBC,EAASC,GAC7B,IAAIuB,EAAU,EACd,OAAOC,EAGP,SAASA,EAAOtB,GACd,OAAa,KAATA,EACKH,EAAQc,MACbC,EACAd,EACAyB,EAHK1B,CAILG,IAGS,KAATA,GACFqB,IAGW,KAATrB,EACKH,EAAQc,MACbI,EACAS,EACAD,EAHK1B,CAILG,GAGAyB,EAAQzB,GACHF,EAAGE,GAGR0B,EAAoB1B,GACfH,EAAQc,MAAMI,EAAajB,EAAIyB,EAA/B1B,CAAqDG,IAG9DH,EAAQI,QAAQD,GACTsB,IAIT,SAASC,EAAqBvB,GAE5B,OADAH,EAAQI,QAAQD,GACTsB,EAIT,SAASE,EAAexB,GAEtB,OADAqB,IACOA,EAAU,EAAIvB,EAAGE,GAAQuB,EAAqBvB,KAhcvDO,SAAS,GAELQ,EAAc,CAClBnB,SAmeF,SAA6BC,EAASC,EAAIC,GACxC,OAGA,SAAeC,GAEb,OADAH,EAAQI,QAAQD,GACTK,GAIT,SAASA,EAAML,GAEb,OAAI0B,EAAoB1B,IACtBH,EAAQI,QAAQD,GACTK,GAIFoB,EAAQzB,GAAQF,EAAGE,GAAQD,EAAIC,KApfxCO,SAAS,GAELK,EAA0B,CAC9BhB,SA8bF,SAAyCC,EAASC,EAAIC,GACpD,OAGA,SAAeC,GAEb,OADAH,EAAQI,QAAQD,GACT2B,GAIT,SAASA,EAAO3B,GACd,OAAI4B,aAAW5B,IACbH,EAAQI,QAAQD,GACT2B,GAGI,KAAT3B,GACFH,EAAQI,QAAQD,GACTK,GAGFN,EAAIC,GAIb,SAASK,EAAML,GAGb,OAAOyB,EAAQzB,GAAQF,EAAGE,GAAQD,EAAIC,KAzdxCO,SAAS,GAELsB,EAAc,CAClBjC,SAwIF,SAA6BC,EAASC,EAAIC,GACxC,MAAM+B,EAAOC,KACb,OAGA,SAAe/B,GACb,GACY,KAATA,GAAwB,MAATA,IACfgC,EAAYF,EAAKG,WAClBC,EAAmBJ,EAAKK,QAExB,OAAOpC,EAAIC,GAQb,OALAH,EAAQuC,MAAM,mBACdvC,EAAQuC,MAAM,sBAIPvC,EAAQc,MACbhB,EACAE,EAAQwC,QAAQ7B,EAAQX,EAAQwC,QAAQjB,EAAMP,GAAOd,GACrDA,EAHKF,CAILG,IAIJ,SAASa,EAAKb,GAGZ,OAFAH,EAAQyC,KAAK,sBACbzC,EAAQyC,KAAK,mBACNxC,EAAGE,KArKZiC,SAAUD,GAENO,EAAe,CACnB3C,SAuKF,SAA8BC,EAASC,EAAIC,GACzC,MAAM+B,EAAOC,KACb,OAGA,SAAe/B,GACb,GACY,KAATA,GAAwB,MAATA,IACfwC,EAAaV,EAAKG,WACnBC,EAAmBJ,EAAKK,QAExB,OAAOpC,EAAIC,GAMb,OAHAH,EAAQuC,MAAM,mBACdvC,EAAQuC,MAAM,uBACdvC,EAAQI,QAAQD,GACTyC,GAIT,SAASA,EAAGzC,GACV,OAAa,KAATA,GAAwB,MAATA,GACjBH,EAAQI,QAAQD,GACT0C,GAGF3C,EAAIC,GAIb,SAAS0C,EAAG1C,GACV,OAAa,KAATA,GAAwB,MAATA,GACjBH,EAAQI,QAAQD,GACT2C,GAGF5C,EAAIC,GAIb,SAAS2C,EAAE3C,GACT,OAAa,KAATA,GAAwB,MAATA,GACjBH,EAAQI,QAAQD,GACT4C,GAGF7C,EAAIC,GAIb,SAAS4C,EAAE5C,GACT,OAAa,KAATA,GAAwB,MAATA,GACjBH,EAAQI,QAAQD,GACT6C,GAGFA,EAAM7C,GAIf,SAAS6C,EAAM7C,GACb,OAAa,KAATA,GACFH,EAAQI,QAAQD,GACT8C,GAGF/C,EAAIC,GAIb,SAAS8C,EAAO9C,GACd,OAAa,KAATA,GACFH,EAAQI,QAAQD,GACT+C,GAGFhD,EAAIC,GAIb,SAAS+C,EAAO/C,GACd,OAAa,KAATA,GACFH,EAAQI,QAAQD,GACTK,GAGFN,EAAIC,GAIb,SAASK,EAAML,GACb,OAAgB,OAATA,GACLgB,eAAahB,IACbiB,oBAAkBjB,IAClBkB,qBAAmBlB,GACjBD,EAAIC,GACJH,EAAQwC,QAAQ7B,EAAQX,EAAQwC,QAAQjB,EAAMP,GAAOd,EAArDF,CAA0DG,GAIhE,SAASa,EAAKb,GAGZ,OAFAH,EAAQyC,KAAK,uBACbzC,EAAQyC,KAAK,mBACNxC,EAAGE,KA9QZiC,SAAUO,GAENQ,EAAgB,CACpBpD,SA8BF,SAA+BC,EAASC,EAAIC,GAC1C,MAAM+B,EAAOC,KAGb,IAAIkB,EAGAC,EACJ,OAGA,SAAelD,GACb,IACGmD,EAASnD,KACToD,EAActB,EAAKG,WACpBC,EAAmBJ,EAAKK,QAExB,OAAOpC,EAAIC,GAKb,OAFAH,EAAQuC,MAAM,mBACdvC,EAAQuC,MAAM,wBACPiB,EAAMrD,IAIf,SAASqD,EAAMrD,GACb,OAAImD,EAASnD,IACXH,EAAQI,QAAQD,GACTqD,GAGI,KAATrD,GACFH,EAAQI,QAAQD,GACTsD,GAGFvD,EAAIC,GAIb,SAASsD,EAAMtD,GACb,OAAa,KAATA,EACKH,EAAQc,MAAMI,EAAaF,EAAM0C,EAAjC1D,CAAkDG,GAG9C,KAATA,GAAwB,KAATA,EACVH,EAAQc,MAAMI,EAAahB,EAAKyD,EAAhC3D,CAA8DG,GAGnEyD,oBAAkBzD,KACfkD,GAAyBQ,aAAW1D,KACvCkD,GAAwB,GAG1BrD,EAAQI,QAAQD,GACTsD,GAGFzC,EAAKb,GAId,SAASuD,EAAgBvD,GAIvB,OAHAH,EAAQI,QAAQD,GAChBiD,GAAS,EACTC,OAAwB/B,EACjBmC,EAIT,SAASE,EAA6BxD,GAEpC,OADAH,EAAQI,QAAQD,GACT2D,EAIT,SAASA,EAAsB3D,GAC7B,OAAa,KAATA,EACKH,EAAQc,MAAMI,EAAahB,EAAKwD,EAAhC1D,CAAiDG,GAGnDsD,EAAMtD,GAIf,SAASa,EAAKb,GACZ,OAAIiD,IAAWC,GACbrD,EAAQyC,KAAK,wBACbzC,EAAQyC,KAAK,mBACNxC,EAAGE,IAGLD,EAAIC,KA1HbiC,SAAUmB,GAINQ,EAAO,GAGAC,EAAqB,CAChCD,KAAAA,GAEF,IAAI5D,EAAO,GAEX,KAAOA,EAAO,KACZ4D,EAAK5D,GAAQgD,EACbhD,IACa,KAATA,EAAaA,EAAO,GACN,KAATA,IAAaA,EAAO,IA4d/B,SAAS0B,EAAoB1B,GAC3B,OACW,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,MAATA,EAQJ,SAASyB,EAAQzB,GACf,OAAgB,OAATA,GAA0B,KAATA,GAAe8D,4BAA0B9D,GAOnE,SAASmD,EAASnD,GAChB,OACW,KAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACAyD,oBAAkBzD,GAKtB,SAASgC,EAAYhC,GACnB,OACW,OAATA,GACS,KAATA,GACS,KAATA,GACS,KAATA,GACS,MAATA,GACA8D,4BAA0B9D,GAK9B,SAASwC,EAAaxC,GACpB,OAAgB,OAATA,IAAkB4B,aAAW5B,GAItC,SAASoD,EAAcpD,GACrB,OAAgB,KAATA,GAAewC,EAAaxC,GAOrC,SAASkC,EAAmBC,GAC1B,IAAI4B,EAAQ5B,EAAO6B,OACfC,GAAS,EAEb,KAAOF,KAAS,CACd,MAAMG,EAAQ/B,EAAO4B,GAAO,GAE5B,IACkB,cAAfG,EAAMC,MAAuC,eAAfD,EAAMC,QACpCD,EAAME,UACP,CACAH,GAAS,EACT,MAIF,GAAIC,EAAMG,8BAA+B,CACvCJ,GAAS,EACT,OAUJ,OANI9B,EAAO6B,OAAS,IAAMC,IAGxB9B,EAAOA,EAAO6B,OAAS,GAAG,GAAGK,+BAAgC,GAGxDJ,EAvjBTL,EAAK,IAAMZ,EACXY,EAAK,IAAMZ,EACXY,EAAK,IAAMZ,EACXY,EAAK,IAAMZ,EACXY,EAAK,IAAM,CAACZ,EAAeT,GAC3BqB,EAAK,KAAO,CAACZ,EAAeT,GAC5BqB,EAAK,IAAM,CAACZ,EAAenB,GAC3B+B,EAAK,KAAO,CAACZ,EAAenB"}